{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocess.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJembU9yd61y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "e19120c8-1895-4071-e1ba-258fe0c65867"
      },
      "source": [
        "!python3 -m pip install xmltodict numpy pandas matplotlib mne scikit-learn scipy joblib autoreject tqdm PyWavelets spectrum xgboost seaborn mock"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.6/dist-packages (0.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n",
            "Requirement already satisfied: mne in /usr/local/lib/python3.6/dist-packages (0.20.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (0.16.0)\n",
            "Requirement already satisfied: autoreject in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: spectrum in /usr/local/lib/python3.6/dist-packages (0.7.6)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (0.10.1)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.6/dist-packages (4.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLfMJEcOdpg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%% #* Import Statements\n",
        "import os\n",
        "import sys\n",
        "import xmltodict\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as sp\n",
        "import matplotlib.pyplot as plt\n",
        "import mne\n",
        "import mock\n",
        "import pywt\n",
        "\n",
        "from tqdm import tqdm as tqdm\n",
        "from spectrum import arburg\n",
        "import sklearn.preprocessing as skpr\n",
        "from scipy import signal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bxnhq9vHgAHI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36b712f2-dbb8-42ee-da1f-8b6d20f1cbdf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F25LYoZGd141",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR = '/content/drive/My Drive/mahnob/Sessions'\n",
        "WINSIZE = 3  # 3 seconds\n",
        "NCHAN = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTkbd897e5vM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getDataFiles(rootFolder):\n",
        "  sessionFolders, sessions = list(sorted(os.listdir(rootFolder))), []\n",
        "  for sessionFolder in sessionFolders:\n",
        "    _path = os.path.join(DATA_DIR, sessionFolder)\n",
        "    if os.path.isdir(_path):\n",
        "      node = {'folder': sessionFolder}\n",
        "      for subfile in os.listdir(_path):\n",
        "        if subfile.endswith('.bdf'):\n",
        "          node['bdf'] = subfile\n",
        "        elif subfile.endswith('.xml'):\n",
        "          node['xml'] = subfile\n",
        "      if 'bdf' in node and 'xml' in node and 'S_Trial' in node['bdf']:\n",
        "        sessions.append(node)\n",
        "  return sessions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AShH0Dke8Vs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%\n",
        "# ratio of the biased standard deviation to the mean\n",
        "def coeff_var(epochs):\n",
        "  return sp.variation(epochs, axis=2)\n",
        "\n",
        "# sharpness of the peak\n",
        "def kurtosis(epochs):\n",
        "  return sp.kurtosis(epochs, axis=2)\n",
        "\n",
        "\n",
        "#! Returns d1_mean, d1_max, d2_mean, d2_max\n",
        "def diff(epochs):\n",
        "  d1, d2 = np.diff(epochs, n=1, axis=2), np.diff(epochs, n=2, axis=2)\n",
        "  return np.mean(\n",
        "      d1, axis=2), np.max(\n",
        "          d1, axis=2), np.mean(\n",
        "              d2, axis=2), np.max(\n",
        "                  d2, axis=2)\n",
        "\n",
        "\n",
        "def skew(epochs):\n",
        "  return sp.skew(epochs, axis=2)\n",
        "\n",
        "\n",
        "def ar_burg(epochs):\n",
        "\n",
        "  model_order = 3\n",
        "\n",
        "  def ar(row):\n",
        "    v1, _, _ = arburg(row, model_order) # Estimate the complex autoregressive parameters by the Burg algorithm.\n",
        "    return v1\n",
        "\n",
        "  def my_arburg(x):\n",
        "    return np.apply_along_axis(lambda x: x.real, 0, ar(x))\n",
        "\n",
        "  abc = np.apply_along_axis(my_arburg, axis=2, arr=epochs)\n",
        "  return [abc[:, :, i] for i in range(model_order)]\n",
        "\n",
        "\n",
        "def hjorth(epochs):\n",
        "  d1 = np.diff(epochs, axis=2)\n",
        "  d2 = np.diff(epochs, axis=2, n=2)\n",
        "  h_activity = np.var(epochs, axis=2)\n",
        "  h_mobility = np.sqrt(np.var(d1, axis=2) / h_activity)\n",
        "  h_mobility_diff = np.sqrt(np.var(d2, axis=2) / np.var(d1, axis=2))\n",
        "  h_complexity = h_mobility_diff / h_mobility\n",
        "  return h_activity, h_mobility, h_complexity\n",
        "\n",
        "\n",
        "def max_power_welch(epochs, sfreq):\n",
        "  BandF = [0.1, 3, 7, 12, 30]\n",
        "  f, Psd = signal.welch(\n",
        "      epochs,\n",
        "      sfreq,\n",
        "  )\n",
        "  return [\n",
        "      np.max(\n",
        "          Psd[:, :, np.where((f > BandF[i]) & (f <= BandF[i + 1]))].squeeze(),\n",
        "          axis=2) for i in range(len(BandF) - 1)\n",
        "  ]\n",
        "\n",
        "\n",
        "def wavelet_features(epochs, nchan=NCHAN):\n",
        "  cA, cD = pywt.dwt(epochs, 'coif1')\n",
        "\n",
        "  def w_mean(c):\n",
        "    return np.mean(c, axis=2)\n",
        "\n",
        "  def w_std(c):\n",
        "    return np.std(c, axis=2)\n",
        "\n",
        "  def w_energy(c):\n",
        "    return np.sum(np.square(c), axis=2)\n",
        "\n",
        "  def w_entropy(c):\n",
        "    return np.sum(np.square(c) * np.log(np.square(c)), axis=2)\n",
        "\n",
        "  feats = [w_mean, w_std, w_energy, w_entropy]\n",
        "  return [feat(c) for c in [cA, cD] for feat in feats]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQtzu11bfWpg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%% #*The MahnobEEG class\n",
        "class MahnobEEG:\n",
        "\n",
        "  def __init__(self, sessionInfo, rootFolder):\n",
        "    self.sessionInfo, self.rootFolder = sessionInfo, rootFolder\n",
        "    self.metafile = '{}/{}/{}'.format(self.rootFolder,\n",
        "                                      self.sessionInfo['folder'],\n",
        "                                      self.sessionInfo['xml'])\n",
        "    self.eegfile = '{}/{}/{}'.format(self.rootFolder,\n",
        "                                     self.sessionInfo['folder'],\n",
        "                                     self.sessionInfo['bdf'])\n",
        "    self.featureFile = '{}/{}/features.pkl'.format(self.rootFolder,\n",
        "                                                   self.sessionInfo['folder'])\n",
        "    self.channels = []\n",
        "\n",
        "  def extractMetadata(self):\n",
        "    emodims = [\n",
        "        '@feltArsl', '@feltCtrl', '@feltEmo', '@feltPred', '@feltVlnc',\n",
        "        '@isStim'\n",
        "    ]\n",
        "    # *Extract metadata into meta\n",
        "    temp = None\n",
        "    with open(self.metafile) as f:\n",
        "      temp = xmltodict.parse('\\n'.join(f.readlines()))\n",
        "    temp = json.loads(json.dumps(temp))['session']\n",
        "    metadata = {\n",
        "        'subjectid': temp['subject']['@id'],\n",
        "        'results': {k[1:]: int(temp[k]) for k in emodims},\n",
        "        'media': {\n",
        "            'name': temp['@mediaFile'],\n",
        "            'durationSec': float(temp['@cutLenSec'])\n",
        "        }\n",
        "    }\n",
        "    self.metadata = metadata\n",
        "\n",
        "  def extractBDF(self):\n",
        "    stdout_old, stderr_old = sys.stdout, sys.stderr\n",
        "    sys.stdout, sys.stderr = mock.MagicMock(), mock.MagicMock()\n",
        "\n",
        "    raw = mne.io.read_raw_bdf(self.eegfile, preload=True, stim_channel='Status')\n",
        "    t20 = mne.channels.make_standard_montage(kind='biosemi32')\n",
        "    raw.set_montage(t20, raise_if_subset=False)\n",
        "    events = mne.find_events(raw, stim_channel='Status')\n",
        "    start_samp, end_samp = events[0][0] + 1, events[1][0] - 1\n",
        "    raw.crop(raw.times[start_samp], raw.times[end_samp])\n",
        "    self.nchan = 32\n",
        "    ch2idx = dict(\n",
        "        map(lambda x: (x[1], x[0]), list(enumerate(raw.ch_names[:self.nchan]))))\n",
        "    raw.pick_channels(raw.ch_names[:self.nchan])\n",
        "    self.ch2idx = dict(\n",
        "        map(lambda x: (x[1], x[0]), list(enumerate(raw.ch_names[:self.nchan]))))\n",
        "    self.df = raw.to_data_frame().rename(columns=ch2idx).T\n",
        "    self.nda = self.df.to_numpy()\n",
        "    # self.nda = self.nda - np.mean(self.nda, axis=-1, keepdims=True)\n",
        "    self.raw = raw\n",
        "    self.nsamp = self.nda.shape[1]\n",
        "    self.sfreq = int(raw.info['sfreq'])\n",
        "    self.samp_step = self.sfreq * WINSIZE\n",
        "    self.chunk_shape = (self.nchan, WINSIZE * self.sfreq)\n",
        "\n",
        "    sys.stdout, sys.stderr = stdout_old, stderr_old\n",
        "\n",
        "  def createEpochs(self):\n",
        "    split_idcs = [\n",
        "        self.chunk_shape[1] * (i + 1)\n",
        "        for i in range(self.nda.shape[1] // self.chunk_shape[1])\n",
        "    ]\n",
        "    epochsArr = np.split(self.nda, split_idcs, axis=1)\n",
        "    #? num_of_epochs * nchan * pts_per_win\n",
        "    self.epochs = np.stack(epochsArr[:-1])\n",
        "\n",
        "  def extract_features(self):\n",
        "    fd = {}\n",
        "    df = pd.DataFrame()\n",
        "    ep = self.epochs\n",
        "    fd['coeff_var'] = coeff_var(ep)\n",
        "    fd['kurtosis'] = kurtosis(ep)\n",
        "    fd['skew'] = skew(ep)\n",
        "    fd['d1_mean'], fd['d1_max'], fd['d2_mean'], fd['d2_max'] = diff(ep)\n",
        "    fd['ar1'], fd['ar2'], fd['ar3'] = ar_burg(ep)\n",
        "\n",
        "    h = 'hjworth_'\n",
        "    fd[f'{h}activity'], fd[f'{h}mobility'], fd[f'{h}complexity'] = hjorth(ep)\n",
        "\n",
        "    a, b, c, d = max_power_welch(ep, self.sfreq)\n",
        "    pr, pm = 'PRatio', 'PMax'\n",
        "    fd[f'{pm}1'], fd[f'{pm}2'], fd[f'{pm}3'], fd[f'{pm}4'] = a, b, c, d\n",
        "    fd[f'{pr}1'], fd[f'{pr}2'], fd[f'{pr}3'], fd[\n",
        "        f'{pr}4'] = a / b, a / c, b / d, (a + b) / c\n",
        "\n",
        "    wvf_names = [\n",
        "        f'{c}_{feat}' for c in ['cA', 'cD']\n",
        "        for feat in ['mean', 'std', 'energy', 'entropy']\n",
        "    ]\n",
        "    wvf_values = wavelet_features(ep)\n",
        "    for i, name in enumerate(wvf_names):\n",
        "      fd[name] = wvf_values[i]\n",
        "\n",
        "    for i in range(self.nchan):\n",
        "      for feat in fd.keys():\n",
        "        df[f'ch{i}_{feat}'] = fd[feat][:, i]\n",
        "\n",
        "    ##\n",
        "    # for feat in fd.keys():\n",
        "    #   df[f'{feat}'] = fd[feat].mean(axis=-1)\n",
        "    ##\n",
        "\n",
        "    df['valence'] = self.metadata['results']['feltVlnc']\n",
        "    df['arousal'] = self.metadata['results']['feltArsl']\n",
        "    df['control'] = self.metadata['results']['feltCtrl']\n",
        "    df['prediction'] = self.metadata['results']['feltPred']\n",
        "    df['emotion'] = self.metadata['results']['feltEmo']\n",
        "    df['stim_video'] = self.metadata['media']['name']\n",
        "    df['subjectid'] = self.metadata['subjectid']\n",
        "\n",
        "    self.features = df\n",
        "\n",
        "  def save_features(self):\n",
        "    self.features.to_pickle(self.featureFile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu_XuSfDfZPr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "b52f88b6-d775-423a-f7f8-bdf932b34f84"
      },
      "source": [
        "#%% #* Extract BDF\n",
        "sessions = getDataFiles(DATA_DIR)\n",
        "for session in tqdm(sessions):\n",
        "  pt = MahnobEEG(session, DATA_DIR)\n",
        "  pt.extractMetadata()\n",
        "  pt.extractBDF()\n",
        "  pt.createEpochs()\n",
        "  pt.extract_features()\n",
        "  pt.save_features()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/527 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:76: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in multiply\n",
            "100%|██████████| 527/527 [1:32:24<00:00, 10.52s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f43vMGiKotGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}